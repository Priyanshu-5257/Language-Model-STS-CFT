# Training

## Applied Techniques
1. Gradient Accumulation : 128 batches (contrastive model requires a large batch size)
2. LoRA : rank 8
3. Mixed Precision Training : bf16
